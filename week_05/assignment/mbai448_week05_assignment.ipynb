{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yw8pGn-ZQF4O"
   },
   "source": [
    "# MBAI 448 | Week 5 Assignment: Transformers and NLP\n",
    "\n",
    "##### Assignment Overview\n",
    "\n",
    "This assignment explores how transformer-based NLP can be applied to a real-world content enrichment problem in media and entertainment. It is organized into three Acts:\n",
    "\n",
    "- Act I: Understand the problem and context\n",
    "- Act II: Prototype a solution with AI technology\n",
    "- Act III: Socialize the work with stakeholders\n",
    "\n",
    "##### Assignment Tools\n",
    "\n",
    "This assignment assumes you will be working with GitHub Copilot in VS Code or Google Colab, and will require you to submit your chat history along with this notebook. If you are curious about how to work effectively with GitHub Copilot, please consult the [VS Code documentation](https://code.visualstudio.com/docs/copilot/overview).\n",
    "\n",
    "Submissions that demonstrate thoughtless interaction with Copilot (e.g., asking Copilot to just read the notebook and produce all the outputs) will receive reduced credit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gF9nXdVoDb7O"
   },
   "source": [
    "## Business Goal / Case Statement\n",
    "Improve traffic and user experience for an online news aggregation platform by enriching and embellishing content.\n",
    "\n",
    "## Assignment Context\n",
    "\n",
    "**Relevant Industry and/or Business Function:** Media and Entertainment\n",
    "\n",
    "**Description:** XYZ Inc. operates a digital platform for news, entertainment, and social content. The company wants to boost traffic and user engagement, in particular among young professionals. Your boss, the Head of News Content, has just brokered a deal with a new provider to acquire commercial news articles. They want you to help build out a business content section, complete with subsections for \"Good News ðŸŽ‰\" and \"Bad News ðŸ‘Ž\" articles, topical tags, pithy summaries, and a clarifying question about each article.\n",
    "\n",
    "## The Data\n",
    "\n",
    "**Data Location:** `'./data/news.csv'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vQvniWqDPLYv"
   },
   "source": [
    "### Act 1: Understand the problem and context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txlEmrGVPScc"
   },
   "source": [
    "#### Step 0: Scope the work in `agents.md`\n",
    "\n",
    "Before moving forward, create a file named `agents.md` in the project root directory (likely the same level of the directory in which this notebook lives). This file specifies the intended role of AI in this project and serves as reference context for GitHub Copilot as you work.\n",
    "\n",
    "Your `agents.md` must include the following five sections:\n",
    "\n",
    "##### 1. What we're building\n",
    "A one-sentence \"elevator pitch\" describing the prototype and its primary output (e.g., \"An automated content enrichment system that classifies, tags, summarizes, and generates FAQs for news articles using transformer-based NLP models.\").\n",
    "\n",
    "##### 2. How AI helps solve the business problem\n",
    "2â€“4 bullet points explaining the specific value-add of the AI components. Focus on the transition from the business \"pain point\" to the AI \"solution.\"\n",
    "\n",
    "##### 3. Key file locations and data structure\n",
    "List the paths that matter (e.g., `./mbai448_week05_assignment.ipynb`, `./data/news.csv`).\n",
    "\n",
    "##### 4. High-level execution plan\n",
    "A step-by-step outline of the build process (e.g., 1. Data loading and inspection, 2. Environment setup and model loading, 3. Sentiment classification, 4. Named entity extraction, 5. Question answering, 6. Summarization, 7. Full pipeline application). Feel free to ask Copilot for help (or take a peek at the steps in Act II below) for a sense of structuring the work.\n",
    "\n",
    "##### 5. Code conventions and constraints\n",
    "To ensure the prototype remains manageable, add 1-2 bullet points specifying that code be as simple and straightforward as possible, using standard libraries unless instructed otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rNgtlfXPoUPt"
   },
   "source": [
    "### Act 2: Prototype a solution with AI technology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJhLYsbv3ezp"
   },
   "source": [
    "## Prototyping a Transformer-Based NLP Pipeline for Content Enrichment\n",
    "\n",
    "In this act, you will prototype a content enrichment system using pretrained transformer models from HuggingFace. The goal is not to build a production system, but to understand how these models behave when applied to real content.\n",
    "\n",
    "Throughout this act, use GitHub Copilot as a development assistant, following a disciplined loop in every step:\n",
    "\n",
    "- **Plan**: Have Copilot draft a clear, plain-language plan describing what needs to happen and in what order.\n",
    "- **Validate**: Review and refine that plan to ensure it does exactly what the step requiresâ€”no more, no less.\n",
    "- **Execute**: Have Copilot implement the validated plan in code.\n",
    "- **Check**: Perform one or two concrete actions that confirm the code worked and that you understand the result.\n",
    "\n",
    "This is exploratory prototyping. The goal is to remain in contact with the system's real behavior at all times.\n",
    "\n",
    "---\n",
    "\n",
    "#### Environment Setup\n",
    "\n",
    "To run this notebook in Google Colab, you'll need to connect to Google Drive and install the required packages.\n",
    "\n",
    "If running locally in VS Code, you may want to create and activate a Python virtual environment.\n",
    "\n",
    "##### On MacOS/Linux:\n",
    "```\n",
    "python -m venv venv\n",
    "source venv/bin/activate\n",
    "```\n",
    "\n",
    "##### On Windows:\n",
    "```\n",
    "python -m venv venv\n",
    "venv\\Scripts\\activate\n",
    "```\n",
    "\n",
    "Once your virtual environment is activated, you can set it as the kernel for this notebook in the top right corner of your notebook pane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3EwhhDZ_3glA"
   },
   "source": [
    "---\n",
    "\n",
    "## Step 1: Load and inspect the article data\n",
    "\n",
    "Before using any model, you need to understand what data you are working with and how it is organized.\n",
    "\n",
    "### Plan\n",
    "Have Copilot create a plan to:\n",
    "- install the transformers library\n",
    "- import required libraries (pandas, transformers pipeline)\n",
    "- load the news dataset from disk\n",
    "- display dataset structure and sample rows\n",
    "\n",
    "### Validate\n",
    "Ensure the plan:\n",
    "- makes dataset structure visible rather than implicit\n",
    "- shows actual article headlines and text\n",
    "- confirms data types and column names\n",
    "\n",
    "### Execute\n",
    "Implement the validated plan in code.\n",
    "\n",
    "### Check\n",
    "- Print the number of articles in the dataset.\n",
    "- Display a few sample rows using head() or tail().\n",
    "\n",
    "**Food for thought:** What kinds of articles are in this dataset? What variation in length and style do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write Step 1 code below\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kI46IqrBPLYy"
   },
   "source": [
    "---\n",
    "\n",
    "## Step 2: Sample a single article for exploration\n",
    "\n",
    "Before applying models at scale, you should work with a single example to understand model behavior.\n",
    "\n",
    "### Plan\n",
    "Have Copilot create a plan to:\n",
    "- extract a single article's headline and text from the dataset\n",
    "- store them in variables for later use\n",
    "- print both to inspect content\n",
    "\n",
    "### Validate\n",
    "Ensure the plan:\n",
    "- uses proper pandas indexing (e.g., `.at[]` property)\n",
    "- creates reusable variables\n",
    "- displays the full content for inspection\n",
    "\n",
    "### Execute\n",
    "Implement the validated plan in code.\n",
    "\n",
    "### Check\n",
    "- Print the headline and article text.\n",
    "- Confirm you can explain what the article is about.\n",
    "\n",
    "**Food for thought:** How might headline sentiment differ from the sentiment of the full article text?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B244elzAPLYz"
   },
   "outputs": [],
   "source": [
    "# write Step 2 code below\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VtR_Tr9-PLY0"
   },
   "source": [
    "---\n",
    "\n",
    "## Step 3: Load pretrained transformer models\n",
    "\n",
    "You will use four different NLP capabilities. Each requires loading a pretrained model from HuggingFace.\n",
    "\n",
    "### Plan\n",
    "Have Copilot create a plan to:\n",
    "- create a sentiment analysis pipeline with a model different from the walkthrough\n",
    "- create a named entity recognition pipeline with a model different from the walkthrough\n",
    "- create a question-answering pipeline with a model different from the walkthrough\n",
    "- create a summarization pipeline with a model different from the walkthrough\n",
    "\n",
    "Model sources:\n",
    "- Sentiment: https://huggingface.co/models?pipeline_tag=text-classification&sort=trending\n",
    "- NER: https://huggingface.co/models?pipeline_tag=token-classification&sort=trending\n",
    "- QA: https://huggingface.co/models?pipeline_tag=question-answering&sort=trending\n",
    "- Summarization: https://huggingface.co/models?pipeline_tag=summarization&sort=trending\n",
    "\n",
    "### Validate\n",
    "Ensure the plan:\n",
    "- uses different models than the walkthrough\n",
    "- assigns each pipeline to a clearly named variable\n",
    "- documents why each model was chosen\n",
    "\n",
    "### Execute\n",
    "Implement the validated plan in code.\n",
    "\n",
    "### Check\n",
    "- Confirm each pipeline loads without errors.\n",
    "- Note any warnings about model configurations.\n",
    "\n",
    "**Food for thought:** What commonalities do you notice across models for a given task (e.g., BERT variants, distilled models, SQUAD dataset)? Why might you prefer a \"distilled\" model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0kjVXPz0PLY0"
   },
   "outputs": [],
   "source": [
    "# write Step 3 code below\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2FtDq4MBrtQb"
   },
   "source": [
    "---\n",
    "\n",
    "## Step 4: Test each model on your sample article\n",
    "\n",
    "Before applying models at scale, you should understand their behavior on a single example.\n",
    "\n",
    "### Plan\n",
    "Have Copilot create a plan to:\n",
    "- run sentiment analysis on the sample headline\n",
    "- run named entity recognition on the sample article text\n",
    "- run summarization on the sample article text\n",
    "- run question answering with a relevant question about the article\n",
    "\n",
    "### Validate\n",
    "Ensure the plan:\n",
    "- uses the variables created in Step 2\n",
    "- prints readable outputs for each capability\n",
    "- includes confidence scores where available\n",
    "\n",
    "### Execute\n",
    "Run the inference code for each model.\n",
    "\n",
    "### Check\n",
    "- Inspect each model's output.\n",
    "- Confirm you can explain what each model is producing.\n",
    "\n",
    "**Food for thought:** How well does each model perform on your sample? What surprised you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RCihyFGkPLY0"
   },
   "outputs": [],
   "source": [
    "# write Step 4 code below\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-sucEeSPLY1"
   },
   "source": [
    "---\n",
    "\n",
    "## Step 5: Prepare data for scaled processing\n",
    "\n",
    "Running NLP models on large datasets is computationally intensive. You'll work with a manageable sample.\n",
    "\n",
    "### Plan\n",
    "Have Copilot create a plan to:\n",
    "- sample the dataset to approximately 100 rows\n",
    "- reset the index for clean row ordering\n",
    "- verify the reduced dataset size\n",
    "\n",
    "### Validate\n",
    "Ensure the plan:\n",
    "- uses random sampling for representativeness\n",
    "- resets index with drop=True to avoid extra columns\n",
    "- confirms final row count\n",
    "\n",
    "### Execute\n",
    "Implement the data preparation code.\n",
    "\n",
    "### Check\n",
    "- Call describe() to confirm dataset size.\n",
    "- Verify the sample looks representative.\n",
    "\n",
    "**Food for thought:** How might the sample size affect your ability to evaluate model performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7VaqGq_LPLY1"
   },
   "outputs": [],
   "source": [
    "# write Step 5 code below\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NVnkdKJrPLY2"
   },
   "source": [
    "---\n",
    "\n",
    "## Step 6: Classify all articles by sentiment\n",
    "\n",
    "Now you apply sentiment classification to categorize articles for the \"Good News\" and \"Bad News\" sections.\n",
    "\n",
    "### Plan\n",
    "Have Copilot create a plan to:\n",
    "- write a function to classify headline sentiment\n",
    "- map labels to 'Good News ðŸŽ‰', 'Bad News ðŸ‘Ž', or 'Just News ðŸ¤·'\n",
    "- apply the function to create a new 'category' column\n",
    "\n",
    "### Validate\n",
    "Ensure the plan:\n",
    "- handles edge cases (low confidence scores)\n",
    "- uses a confidence threshold for ambiguous cases\n",
    "- creates readable category labels\n",
    "\n",
    "### Execute\n",
    "Implement the classification pipeline.\n",
    "\n",
    "### Check\n",
    "- Display head() to see the new category column.\n",
    "- Sample a few rows to verify classifications make sense.\n",
    "\n",
    "**Food for thought:** What threshold would you use to distinguish confident vs. ambiguous classifications?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QW2LbHaPPLY2"
   },
   "outputs": [],
   "source": [
    "# write Step 6 code below\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 7: Extract named entities as tags for all articles\n",
    "\n",
    "Named entities (people, organizations, locations) serve as topical tags for content discovery.\n",
    "\n",
    "### Plan\n",
    "Have Copilot create a plan to:\n",
    "- write a function to extract unique named entities from text\n",
    "- filter out duplicates and subword tokens\n",
    "- apply the function to create a new 'tags' column\n",
    "\n",
    "### Validate\n",
    "Ensure the plan:\n",
    "- returns a list of unique entity strings\n",
    "- handles articles with no entities gracefully\n",
    "- produces readable tag names\n",
    "\n",
    "### Execute\n",
    "Implement the entity extraction pipeline.\n",
    "\n",
    "### Check\n",
    "- Display tail() to see the new tags column.\n",
    "- Examine a few articles' tags for relevance.\n",
    "\n",
    "**Food for thought:** How might entity types (person, organization, location) be used differently in a content recommendation system?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write Step 7 code below\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 8: Generate a FAQ for each article\n",
    "\n",
    "Question-answering models can generate clarifying questions and answers to enhance reader engagement.\n",
    "\n",
    "### Plan\n",
    "Have Copilot create a plan to:\n",
    "- write a function that generates a relevant question based on article content\n",
    "- use the QA model to find the answer in the article text\n",
    "- apply the function to create a new 'faq' column with Q&A pairs\n",
    "\n",
    "### Validate\n",
    "Ensure the plan:\n",
    "- generates coherent, relevant questions\n",
    "- returns both question and answer in a structured format\n",
    "- handles cases where no good answer is found\n",
    "\n",
    "### Execute\n",
    "Implement the FAQ generation pipeline.\n",
    "\n",
    "### Check\n",
    "- Display head() to see the new faq column.\n",
    "- Use .at[] to inspect individual FAQ entries in detail.\n",
    "\n",
    "**Food for thought:** How might you compose the question differently based on article category?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write Step 8 code below\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 9: Summarize all articles\n",
    "\n",
    "Pithy summaries help readers quickly assess article relevance.\n",
    "\n",
    "### Plan\n",
    "Have Copilot create a plan to:\n",
    "- write a function to summarize article text\n",
    "- handle text length constraints (some models have max token limits)\n",
    "- apply the function to create a new 'summary' column\n",
    "\n",
    "### Validate\n",
    "Ensure the plan:\n",
    "- truncates long articles to avoid errors (e.g., first 5000 characters)\n",
    "- produces summaries significantly shorter than originals\n",
    "- handles edge cases gracefully\n",
    "\n",
    "### Execute\n",
    "Implement the summarization pipeline.\n",
    "\n",
    "### Check\n",
    "- Display tail() to see the new summary column.\n",
    "- Compare a summary to its original article using .at[].\n",
    "\n",
    "**Food for thought:** How would you evaluate whether a summary preserves the key information?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write Step 9 code below\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H99hSQyOPLY2"
   },
   "source": [
    "---\n",
    "\n",
    "## Step 10: Review the enriched dataset and reflect on scalability\n",
    "\n",
    "You now have a fully enriched dataset. Assess the results and consider production implications.\n",
    "\n",
    "### Plan\n",
    "Have Copilot create a plan to:\n",
    "- display the final dataframe structure with all new columns\n",
    "- sample individual records to inspect quality\n",
    "- document observations about model behavior\n",
    "\n",
    "### Validate\n",
    "Ensure the plan:\n",
    "- shows all columns including original and enriched data\n",
    "- allows inspection of individual records in detail\n",
    "- prompts reflection on scaling considerations\n",
    "\n",
    "### Execute\n",
    "Review the final enriched dataset.\n",
    "\n",
    "### Check\n",
    "- Confirm all expected columns are present.\n",
    "- Inspect 2-3 individual records across different categories.\n",
    "\n",
    "**Food for thought:** If your boss asks you to scale this across millions of articles, how would you answer? What would you useâ€”models like these or GPT-4o/DeepSeek-v3? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qYVVoeL8PLY3"
   },
   "outputs": [],
   "source": [
    "# write Step 10 code below\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## End of Act II\n",
    "\n",
    "At this point, you should have direct evidence of how pretrained transformer models behave on your content, what each NLP capability produces, and what quality/performance tradeoffs exist. Use these observations to inform Act III discussions with stakeholders.\n",
    "\n",
    "Before moving on to Act III, create a file named `README.md` in the project root.\n",
    "\n",
    "This README should capture the current state of the prototype as if you were handing it off to a colleague. Keep it concise and grounded in what actually exists.\n",
    "\n",
    "### 1. What this prototype does\n",
    "In one sentence, clearly describe the capability that was built and the problem it is intended to address.\n",
    "\n",
    "### 2. How it works (at a high level)\n",
    "In a few bullet points, specify:\n",
    "- what data the system operates over,\n",
    "- what models or representations it uses,\n",
    "- how results are produced.\n",
    "\n",
    "### 3. Limitations and open questions\n",
    "Briefly note:\n",
    "- the most important limitations you observed or conceive of, and\n",
    "- any open questions that would need to be addressed before broader use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Act 3 â€” Socialize the Work\n",
    "\n",
    "You have built and evaluated a working prototype for automated content enrichment. Now you need to think about what it would mean to use this system in practice.\n",
    "\n",
    "In this act, you will have conversations with three colleagues who each engage with the system from a different professional perspective. Each one surfaces a distinct set of pressures that emerge when NLP automation is introduced into a real content operation.\n",
    "\n",
    "Your goal is not to convince them that the system is \"good,\" but to reckon with how its behavior intersects with editorial judgment, organizational responsibility, and operational reality.\n",
    "\n",
    "---\n",
    "\n",
    "### Colleague Perspectives\n",
    "\n",
    "You will speak with:\n",
    "\n",
    "- A **Content Strategy Lead** focused on how automated tagging and categorization changes editorial workflows â€” including when editors trust the system, when they override it, and how errors affect content quality and reader trust.\n",
    "\n",
    "- An **Editorial Standards Manager** focused on accountability, accuracy, and brand risk â€” including what happens when articles are miscategorized or summaries misrepresent content, how decisions are justified after the fact, and whether the system can be relied on for sensitive topics.\n",
    "\n",
    "- A **Platform Operations Manager** focused on efficiency and scale â€” including the tradeoffs between processing speed and accuracy, how the system affects content throughput, and whether gains in automation introduce new forms of friction elsewhere in the pipeline.\n",
    "\n",
    "---\n",
    "\n",
    "### How to Approach These Conversations\n",
    "\n",
    "Each conversation should feel like a real internal discussion about a live prototype.\n",
    "\n",
    "In these interactions, you should be prepared to:\n",
    "- explain how each model behaves in concrete terms,\n",
    "- reference evidence from your prototype (e.g., sample classifications, entity extractions, summaries),\n",
    "- articulate tradeoffs clearly in plain, cross-functional language,\n",
    "- and acknowledge uncertainty where it exists.\n",
    "\n",
    "These colleagues are not trying to block the work â€” but they are responsible for understanding its implications within their domains.\n",
    "\n",
    "When a colleague has enough information to understand the risks, assumptions, and consequences involved, the conversation will naturally come to a close."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ou_BCTdpsTOZ"
   },
   "source": [
    "---\n",
    "\n",
    "### Submission\n",
    "\n",
    "- Save the Notebook you have been working in and other files you created in your repo (i.e., `agents.md`, `README.md`, etc).\n",
    "- Export your Copilot Chat and save as a `.txt`, `.json`, or `.md` in the same directory as the above.\n",
    "- Stop / shut down the Google Colab session in which the Notebook was running.\n",
    "- **Upload your completed Notebook to the [Canvas page for Assignment 5](https://canvas.northwestern.edu/courses/245397/assignments/1668984).**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
