{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5862e7cf",
   "metadata": {},
   "source": [
    "# Sentiment-Based News Sorter Prototype\n",
    "\n",
    "This notebook demonstrates a prototype for classifying news articles as \"Good News ðŸŽ‰\", \"Bad News ðŸ‘Ž\", or \"Just News ðŸ¤·\" using transformer-based NLP models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadaff42",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "Import the necessary libraries, including pandas and transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a02ceb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\github\\mbai-448\\.venv\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: transformers in c:\\github\\mbai-448\\.venv\\lib\\site-packages (5.1.0)\n",
      "Requirement already satisfied: numpy>=2.3.3 in c:\\github\\mbai-448\\.venv\\lib\\site-packages (from pandas) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\github\\mbai-448\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata in c:\\github\\mbai-448\\.venv\\lib\\site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=1.3.0 in c:\\github\\mbai-448\\.venv\\lib\\site-packages (from transformers) (1.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\github\\mbai-448\\.venv\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\github\\mbai-448\\.venv\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\github\\mbai-448\\.venv\\lib\\site-packages (from transformers) (2026.1.15)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\github\\mbai-448\\.venv\\lib\\site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: typer-slim in c:\\github\\mbai-448\\.venv\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\github\\mbai-448\\.venv\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\github\\mbai-448\\.venv\\lib\\site-packages (from transformers) (4.67.3)\n",
      "Requirement already satisfied: filelock in c:\\github\\mbai-448\\.venv\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (3.20.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\github\\mbai-448\\.venv\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (2026.1.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in c:\\github\\mbai-448\\.venv\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\github\\mbai-448\\.venv\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (0.28.1)\n",
      "Requirement already satisfied: shellingham in c:\\github\\mbai-448\\.venv\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.5.4)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\github\\mbai-448\\.venv\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: anyio in c:\\github\\mbai-448\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (4.12.1)\n",
      "Requirement already satisfied: certifi in c:\\github\\mbai-448\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\github\\mbai-448\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\github\\mbai-448\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\github\\mbai-448\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (0.16.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\github\\mbai-448\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\github\\mbai-448\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\github\\mbai-448\\.venv\\lib\\site-packages (from typer-slim->transformers) (8.3.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries if not already installed\n",
    "!pip install pandas transformers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c04bd348",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\mbai-448\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6041a75a",
   "metadata": {},
   "source": [
    "## 2. Load and Inspect the News Data\n",
    "Load the news dataset and inspect its structure and sample rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ade5801b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles: 510\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UK economy facing 'major risks'</td>\n",
       "      <td>The UK manufacturing sector will continue to f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aids and climate top Davos agenda</td>\n",
       "      <td>Climate change and the fight against Aids are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Asian quake hits European shares</td>\n",
       "      <td>Shares in Europe's leading reinsurers and trav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India power shares jump on debut</td>\n",
       "      <td>Shares in India's largest power producer, Nati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lacroix label bought by US firm</td>\n",
       "      <td>Luxury goods group LVMH has sold its loss-maki...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            headline  \\\n",
       "0    UK economy facing 'major risks'   \n",
       "1  Aids and climate top Davos agenda   \n",
       "2   Asian quake hits European shares   \n",
       "3   India power shares jump on debut   \n",
       "4    Lacroix label bought by US firm   \n",
       "\n",
       "                                                text  \n",
       "0  The UK manufacturing sector will continue to f...  \n",
       "1  Climate change and the fight against Aids are ...  \n",
       "2  Shares in Europe's leading reinsurers and trav...  \n",
       "3  Shares in India's largest power producer, Nati...  \n",
       "4  Luxury goods group LVMH has sold its loss-maki...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headline    str\n",
      "text        str\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Load the news dataset\n",
    "news_df = pd.read_csv('./data/news.csv')\n",
    "\n",
    "# Display dataset structure and sample rows\n",
    "print(f\"Number of articles: {len(news_df)}\")\n",
    "display(news_df.head())\n",
    "print(news_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2506f10e",
   "metadata": {},
   "source": [
    "## 3. Set Up Sentiment Analysis Pipeline\n",
    "Load a transformer-based sentiment analysis model from HuggingFace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cca8464",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "c:\\GitHub\\mbai-448\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:130: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sbudh\\.cache\\huggingface\\hub\\models--distilbert-base-uncased-finetuned-sst-2-english. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 104/104 [00:00<00:00, 398.65it/s, Materializing param=pre_classifier.weight]                                  \n"
     ]
    }
   ],
   "source": [
    "# Load a sentiment analysis pipeline (using a popular model from HuggingFace)\n",
    "sentiment_analyzer = pipeline('sentiment-analysis', model='distilbert-base-uncased-finetuned-sst-2-english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0307d2a5",
   "metadata": {},
   "source": [
    "## 4. Classify Article Sentiment and Map to Categories\n",
    "Apply the sentiment model to each article and map results to 'Good News ðŸŽ‰', 'Bad News ðŸ‘Ž', or 'Just News ðŸ¤·'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cacf1c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to map sentiment to news categories\n",
    "def map_sentiment_to_category(sentiment_label, score, threshold=0.7):\n",
    "    if sentiment_label == 'POSITIVE' and score >= threshold:\n",
    "        return 'Good News ðŸŽ‰'\n",
    "    elif sentiment_label == 'NEGATIVE' and score >= threshold:\n",
    "        return 'Bad News ðŸ‘Ž'\n",
    "    else:\n",
    "        return 'Just News ðŸ¤·'\n",
    "\n",
    "# Apply sentiment analysis to headlines (or use 'title' if that's the column name)\n",
    "results = sentiment_analyzer(list(news_df['headline']))\n",
    "\n",
    "# Add results to DataFrame\n",
    "news_df['sentiment_label'] = [r['label'] for r in results]\n",
    "news_df['sentiment_score'] = [r['score'] for r in results]\n",
    "news_df['category'] = [map_sentiment_to_category(r['label'], r['score']) for r in results]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a430283d",
   "metadata": {},
   "source": [
    "## 5. Review and Visualize Results\n",
    "Display the enriched dataset and sample the categorized news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "026ac2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            headline sentiment_label  sentiment_score  \\\n",
      "0    UK economy facing 'major risks'        NEGATIVE         0.963595   \n",
      "1  Aids and climate top Davos agenda        NEGATIVE         0.741379   \n",
      "2   Asian quake hits European shares        POSITIVE         0.992087   \n",
      "3   India power shares jump on debut        POSITIVE         0.999317   \n",
      "4    Lacroix label bought by US firm        NEGATIVE         0.982360   \n",
      "\n",
      "      category  \n",
      "0   Bad News ðŸ‘Ž  \n",
      "1   Bad News ðŸ‘Ž  \n",
      "2  Good News ðŸŽ‰  \n",
      "3  Good News ðŸŽ‰  \n",
      "4   Bad News ðŸ‘Ž  \n",
      "category\n",
      "Bad News ðŸ‘Ž     299\n",
      "Good News ðŸŽ‰    188\n",
      "Just News ðŸ¤·     23\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display a few sample rows with categories\n",
    "print(news_df[['headline', 'sentiment_label', 'sentiment_score', 'category']].head())\n",
    "\n",
    "# Show category distribution\n",
    "print(news_df['category'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea949dc7",
   "metadata": {},
   "source": [
    "## 6. Improved Sentiment Labeling: Use Article Text and Alternative Model\n",
    "\n",
    "To address limitations, we will:\n",
    "- Use the full article text for sentiment analysis (falling back to headline if text is missing).\n",
    "- Try an alternative transformer model (e.g., cardiffnlp/twitter-roberta-base-sentiment-latest) for comparison.\n",
    "- Add a flag for low-confidence predictions for potential manual review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6dc0a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\mbai-448\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:130: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\sbudh\\.cache\\huggingface\\hub\\models--cardiffnlp--twitter-roberta-base-sentiment-latest. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 201/201 [00:00<00:00, 459.12it/s, Materializing param=roberta.encoder.layer.11.output.dense.weight]              \n",
      "\u001b[1mRobertaForSequenceClassification LOAD REPORT\u001b[0m from: cardiffnlp/twitter-roberta-base-sentiment-latest\n",
      "Key                             | Status     |  | \n",
      "--------------------------------+------------+--+-\n",
      "roberta.pooler.dense.bias       | UNEXPECTED |  | \n",
      "roberta.embeddings.position_ids | UNEXPECTED |  | \n",
      "roberta.pooler.dense.weight     | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install and import alternative model if needed\n",
    "# !pip install transformers torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Load alternative sentiment model (CardiffNLP's Twitter RoBERTa)\n",
    "model_name = 'cardiffnlp/twitter-roberta-base-sentiment-latest'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Helper function for sentiment prediction\n",
    "def get_sentiment_label(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    scores = torch.softmax(logits, dim=1).numpy()[0]\n",
    "    labels = ['Negative', 'Neutral', 'Positive']\n",
    "    max_idx = np.argmax(scores)\n",
    "    return labels[max_idx], float(scores[max_idx]), float(np.max(scores))\n",
    "\n",
    "# Use article text if available, else headline\n",
    "def get_text(row):\n",
    "    if pd.notnull(row.get('content', None)) and str(row['content']).strip():\n",
    "        return str(row['content'])\n",
    "    return str(row['headline'])\n",
    "\n",
    "# Apply improved sentiment analysis\n",
    "sentiment_results = news_df.apply(lambda row: get_sentiment_label(get_text(row)), axis=1)\n",
    "news_df['alt_sentiment_label'] = [r[0] for r in sentiment_results]\n",
    "news_df['alt_sentiment_score'] = [r[1] for r in sentiment_results]\n",
    "news_df['alt_sentiment_confidence'] = [r[2] for r in sentiment_results]\n",
    "\n",
    "# Flag low-confidence predictions for manual review\n",
    "confidence_threshold = 0.7\n",
    "news_df['needs_review'] = news_df['alt_sentiment_confidence'] < confidence_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10d5429",
   "metadata": {},
   "source": [
    "## 7. Review Improved Results\n",
    "Display and compare the new sentiment labels, confidence, and review flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8682ec32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            headline alt_sentiment_label  alt_sentiment_score  \\\n",
      "0    UK economy facing 'major risks'            Negative             0.605086   \n",
      "1  Aids and climate top Davos agenda             Neutral             0.682842   \n",
      "2   Asian quake hits European shares             Neutral             0.649496   \n",
      "3   India power shares jump on debut            Positive             0.833764   \n",
      "4    Lacroix label bought by US firm             Neutral             0.906590   \n",
      "\n",
      "   alt_sentiment_confidence  needs_review  \n",
      "0                  0.605086          True  \n",
      "1                  0.682842          True  \n",
      "2                  0.649496          True  \n",
      "3                  0.833764         False  \n",
      "4                  0.906590         False  \n",
      "alt_sentiment_label\n",
      "Neutral     353\n",
      "Negative     98\n",
      "Positive     59\n",
      "Name: count, dtype: int64\n",
      "Articles flagged for review: 214 out of 510\n"
     ]
    }
   ],
   "source": [
    "# Show a sample of improved results\n",
    "print(news_df[['headline', 'alt_sentiment_label', 'alt_sentiment_score', 'alt_sentiment_confidence', 'needs_review']].head())\n",
    "\n",
    "# Show distribution of new sentiment labels\n",
    "print(news_df['alt_sentiment_label'].value_counts())\n",
    "\n",
    "# Show how many articles need manual review\n",
    "print(f\"Articles flagged for review: {news_df['needs_review'].sum()} out of {len(news_df)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
