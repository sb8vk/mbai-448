{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "288109ec",
   "metadata": {},
   "source": [
    "# Execute Sentiment-Based News Enrichment Plan\n",
    "\n",
    "This notebook executes the updated high-level plan for automated news enrichment using transformer-based NLP models. Each section corresponds to a major step in the workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de21bd5a",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "Import standard libraries and all required modules for plan execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "038e8ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\mbai-448\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# HuggingFace transformers\n",
    "from transformers import pipeline\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a99f63b",
   "metadata": {},
   "source": [
    "## 2. Load and Explore the Plan\n",
    "\n",
    "Load the high-level plan and display its structure for review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70d581f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Data loading and inspection\n",
      "Step 2: Environment setup and model loading\n",
      "Step 3: Sample a single article for exploration\n",
      "Step 4: Load pretrained transformer models\n",
      "Step 5: Test the models on your sample article\n",
      "Step 6: Prepare data for scaled processing\n",
      "Step 7: Classify all articles by sentiment\n",
      "Step 8: Extract named entities as tags\n",
      "Step 9: Generate a FAQ for each article\n",
      "Step 10: Summarize all articles\n",
      "Step 11: Visualize and review results\n",
      "Step 12: Export enriched dataset\n",
      "Step 13: (Optional) Self-learning for model improvement\n"
     ]
    }
   ],
   "source": [
    "# Define the high-level plan as a list of steps (from agents.md)\n",
    "plan_steps = [\n",
    "    \"Data loading and inspection\",\n",
    "    \"Environment setup and model loading\",\n",
    "    \"Sample a single article for exploration\",\n",
    "    \"Load pretrained transformer models\",\n",
    "    \"Test the models on your sample article\",\n",
    "    \"Prepare data for scaled processing\",\n",
    "    \"Classify all articles by sentiment\",\n",
    "    \"Extract named entities as tags\",\n",
    "    \"Generate a FAQ for each article\",\n",
    "    \"Summarize all articles\",\n",
    "    \"Visualize and review results\",\n",
    "    \"Export enriched dataset\",\n",
    "    \"(Optional) Self-learning for model improvement\"\n",
    "]\n",
    "\n",
    "# Display the plan\n",
    "for i, step in enumerate(plan_steps, 1):\n",
    "    print(f\"Step {i}: {step}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bf7ac3",
   "metadata": {},
   "source": [
    "## 3. Execute Plan Steps Programmatically\n",
    "\n",
    "Iterate through each step in the plan and execute the corresponding code or command. Capture outputs for each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0a92045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 510 articles.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UK economy facing 'major risks'</td>\n",
       "      <td>The UK manufacturing sector will continue to f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aids and climate top Davos agenda</td>\n",
       "      <td>Climate change and the fight against Aids are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Asian quake hits European shares</td>\n",
       "      <td>Shares in Europe's leading reinsurers and trav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India power shares jump on debut</td>\n",
       "      <td>Shares in India's largest power producer, Nati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lacroix label bought by US firm</td>\n",
       "      <td>Luxury goods group LVMH has sold its loss-maki...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            headline  \\\n",
       "0    UK economy facing 'major risks'   \n",
       "1  Aids and climate top Davos agenda   \n",
       "2   Asian quake hits European shares   \n",
       "3   India power shares jump on debut   \n",
       "4    Lacroix label bought by US firm   \n",
       "\n",
       "                                                text  \n",
       "0  The UK manufacturing sector will continue to f...  \n",
       "1  Climate change and the fight against Aids are ...  \n",
       "2  Shares in Europe's leading reinsurers and trav...  \n",
       "3  Shares in India's largest power producer, Nati...  \n",
       "4  Luxury goods group LVMH has sold its loss-maki...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1: Data loading and inspection\n",
    "try:\n",
    "    news_df = pd.read_csv('./data/news.csv')\n",
    "    print(f\"Loaded {len(news_df)} articles.\")\n",
    "    display(news_df.head())\n",
    "except Exception as e:\n",
    "    logging.error(f\"Failed to load news.csv: {e}\")\n",
    "    news_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c790b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: HEAD https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO: HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/cardiffnlp/twitter-roberta-base-sentiment-latest/3216a57f2a0d9c45a2e6c20157c20c49fb4bf9c7/config.json \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: HEAD https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest/resolve/main/model.safetensors \"HTTP/1.1 404 Not Found\"\n",
      "INFO: HTTP Request: GET https://huggingface.co/api/models/cardiffnlp/twitter-roberta-base-sentiment-latest \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: GET https://huggingface.co/api/models/cardiffnlp/twitter-roberta-base-sentiment-latest/commits/main \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: GET https://huggingface.co/api/models/cardiffnlp/twitter-roberta-base-sentiment-latest/discussions?p=0 \"HTTP/1.1 200 OK\"\n",
      "Loading weights:  11%|â–ˆ         | 22/201 [00:00<00:00, 471.43it/s, Materializing param=roberta.encoder.layer.0.output.LayerNorm.bias]INFO: HTTP Request: GET https://huggingface.co/api/models/cardiffnlp/twitter-roberta-base-sentiment-latest/commits/refs%2Fpr%2F43 \"HTTP/1.1 200 OK\"\n",
      "Loading weights:  25%|â–ˆâ–ˆâ–       | 50/201 [00:00<00:00, 426.51it/s, Materializing param=roberta.encoder.layer.2.attention.self.value.bias]  INFO: HTTP Request: HEAD https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest/resolve/refs%2Fpr%2F43/model.safetensors.index.json \"HTTP/1.1 404 Not Found\"\n",
      "Loading weights:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 80/201 [00:00<00:00, 426.51it/s, Materializing param=roberta.encoder.layer.4.attention.self.query.bias]INFO: HTTP Request: HEAD https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest/resolve/refs%2Fpr%2F43/model.safetensors \"HTTP/1.1 302 Found\"\n",
      "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 201/201 [00:00<00:00, 418.80it/s, Materializing param=roberta.encoder.layer.11.output.dense.weight]              \n",
      "\u001b[1mRobertaForSequenceClassification LOAD REPORT\u001b[0m from: cardiffnlp/twitter-roberta-base-sentiment-latest\n",
      "Key                             | Status     |  | \n",
      "--------------------------------+------------+--+-\n",
      "roberta.embeddings.position_ids | UNEXPECTED |  | \n",
      "roberta.pooler.dense.weight     | UNEXPECTED |  | \n",
      "roberta.pooler.dense.bias       | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n",
      "INFO: HTTP Request: GET https://huggingface.co/api/models/cardiffnlp/twitter-roberta-base-sentiment-latest/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 404 Not Found\"\n",
      "INFO: HTTP Request: GET https://huggingface.co/api/models/cardiffnlp/twitter-roberta-base-sentiment-latest/tree/main?recursive=true&expand=false \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: HEAD https://huggingface.co/dslim/bert-base-NER/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO: HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/dslim/bert-base-NER/d1a3e8f13f8c3566299d95fcfc9a8d2382a9affc/config.json \"HTTP/1.1 200 OK\"\n",
      "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 199/199 [00:00<00:00, 361.31it/s, Materializing param=classifier.weight]                                      \n",
      "\u001b[1mBertForTokenClassification LOAD REPORT\u001b[0m from: dslim/bert-base-NER\n",
      "Key                      | Status     |  | \n",
      "-------------------------+------------+--+-\n",
      "bert.pooler.dense.weight | UNEXPECTED |  | \n",
      "bert.pooler.dense.bias   | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n",
      "INFO: HTTP Request: GET https://huggingface.co/api/models/dslim/bert-base-NER/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 404 Not Found\"\n",
      "INFO: HTTP Request: GET https://huggingface.co/api/models/dslim/bert-base-NER/tree/main?recursive=true&expand=false \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: HEAD https://huggingface.co/deepset/roberta-base-squad2/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO: HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/deepset/roberta-base-squad2/adc3b06f79f797d1c575d5479d6f5efe54a9e3b4/config.json \"HTTP/1.1 200 OK\"\n",
      "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 199/199 [00:00<00:00, 391.37it/s, Materializing param=roberta.encoder.layer.11.output.dense.weight]              \n",
      "\u001b[1mRobertaForQuestionAnswering LOAD REPORT\u001b[0m from: deepset/roberta-base-squad2\n",
      "Key                             | Status     |  | \n",
      "--------------------------------+------------+--+-\n",
      "roberta.embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n",
      "INFO: HTTP Request: GET https://huggingface.co/api/models/deepset/roberta-base-squad2/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 404 Not Found\"\n",
      "INFO: HTTP Request: GET https://huggingface.co/api/models/deepset/roberta-base-squad2/tree/main?recursive=true&expand=false \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: HEAD https://huggingface.co/deepset/roberta-base-squad2/resolve/main/processor_config.json \"HTTP/1.1 404 Not Found\"\n",
      "INFO: HTTP Request: HEAD https://huggingface.co/deepset/roberta-base-squad2/resolve/main/preprocessor_config.json \"HTTP/1.1 404 Not Found\"\n",
      "INFO: HTTP Request: HEAD https://huggingface.co/deepset/roberta-base-squad2/resolve/main/processor_config.json \"HTTP/1.1 404 Not Found\"\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "WARNING: Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "INFO: HTTP Request: HEAD https://huggingface.co/deepset/roberta-base-squad2/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO: HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/deepset/roberta-base-squad2/adc3b06f79f797d1c575d5479d6f5efe54a9e3b4/config.json \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: HEAD https://huggingface.co/deepset/roberta-base-squad2/resolve/main/processor_config.json \"HTTP/1.1 404 Not Found\"\n",
      "INFO: HTTP Request: HEAD https://huggingface.co/deepset/roberta-base-squad2/resolve/main/preprocessor_config.json \"HTTP/1.1 404 Not Found\"\n",
      "INFO: HTTP Request: HEAD https://huggingface.co/deepset/roberta-base-squad2/resolve/main/processor_config.json \"HTTP/1.1 404 Not Found\"\n",
      "INFO: HTTP Request: HEAD https://huggingface.co/deepset/roberta-base-squad2/resolve/main/preprocessor_config.json \"HTTP/1.1 404 Not Found\"\n",
      "INFO: HTTP Request: HEAD https://huggingface.co/deepset/roberta-base-squad2/resolve/main/video_preprocessor_config.json \"HTTP/1.1 404 Not Found\"\n",
      "INFO: HTTP Request: HEAD https://huggingface.co/deepset/roberta-base-squad2/resolve/main/preprocessor_config.json \"HTTP/1.1 404 Not Found\"\n",
      "INFO: HTTP Request: HEAD https://huggingface.co/deepset/roberta-base-squad2/resolve/main/tokenizer_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO: HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/deepset/roberta-base-squad2/adc3b06f79f797d1c575d5479d6f5efe54a9e3b4/tokenizer_config.json \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: GET https://huggingface.co/api/models/deepset/roberta-base-squad2/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 404 Not Found\"\n",
      "INFO: HTTP Request: GET https://huggingface.co/api/models/deepset/roberta-base-squad2/tree/main?recursive=true&expand=false \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: HEAD https://huggingface.co/gpt2/resolve/main/config.json \"HTTP/1.1 200 OK\"\n",
      "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 148/148 [00:00<00:00, 353.72it/s, Materializing param=transformer.wte.weight]             \n",
      "\u001b[1mGPT2LMHeadModel LOAD REPORT\u001b[0m from: gpt2\n",
      "Key                  | Status     |  | \n",
      "---------------------+------------+--+-\n",
      "h.{0...11}.attn.bias | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n",
      "INFO: HTTP Request: HEAD https://huggingface.co/gpt2/resolve/main/generation_config.json \"HTTP/1.1 200 OK\"\n",
      "INFO: HTTP Request: GET https://huggingface.co/api/models/gpt2/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO: HTTP Request: GET https://huggingface.co/api/models/openai-community/gpt2/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 404 Not Found\"\n",
      "INFO: HTTP Request: GET https://huggingface.co/api/models/gpt2/tree/main?recursive=true&expand=false \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO: HTTP Request: GET https://huggingface.co/api/models/openai-community/gpt2/tree/main?recursive=true&expand=false \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All models loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Environment setup and model loading\n",
    "try:\n",
    "    sentiment_model = pipeline('sentiment-analysis', model='cardiffnlp/twitter-roberta-base-sentiment-latest')\n",
    "    ner_model = pipeline('ner', model='dslim/bert-base-NER')\n",
    "    qa_model = pipeline('question-answering', model='deepset/roberta-base-squad2')\n",
    "    summarizer = pipeline('text-generation', model='gpt2')\n",
    "    print(\"All models loaded successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Model loading failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07108435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Headline: UK economy facing 'major risks'\n",
      "\n",
      "Sample Text: The UK manufacturing sector will continue to face \"serious challenges\" over the next two years, the British Chamber of Commerce (BCC) has said.  The group's quarterly survey of companies found exports had picked up in the last three months of 2004 to their best levels in eight years. The rise came despite exchange rates being cited as a major concern. However, the BCC found the whole UK economy still faced \"major risks\" and warned that growth is set to slow. It recently forecast economic growth ...\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Sample a single article for exploration\n",
    "if news_df is not None:\n",
    "    sample_idx = 0\n",
    "    sample_headline = news_df.at[sample_idx, 'headline'] if 'headline' in news_df.columns else news_df.columns[0]\n",
    "    sample_text = news_df.at[sample_idx, 'text'] if 'text' in news_df.columns else news_df.iloc[sample_idx, 1]\n",
    "    print(f\"Sample Headline: {sample_headline}\\n\\nSample Text: {sample_text[:500]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bca5b1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentiment Analysis:\n",
      "[{'label': 'negative', 'score': 0.6050862669944763}]\n",
      "\n",
      "Named Entity Recognition:\n",
      "[{'entity': 'B-LOC', 'score': np.float32(0.99948573), 'index': 2, 'word': 'UK', 'start': 4, 'end': 6}, {'entity': 'B-ORG', 'score': np.float32(0.99933606), 'index': 20, 'word': 'British', 'start': 100, 'end': 107}, {'entity': 'I-ORG', 'score': np.float32(0.9990872), 'index': 21, 'word': 'Chamber', 'start': 108, 'end': 115}, {'entity': 'I-ORG', 'score': np.float32(0.9994103), 'index': 22, 'word': 'of', 'start': 116, 'end': 118}, {'entity': 'I-ORG', 'score': np.float32(0.9992132), 'index': 23, 'word': 'Commerce', 'start': 119, 'end': 127}, {'entity': 'B-ORG', 'score': np.float32(0.99925035), 'index': 25, 'word': 'BC', 'start': 129, 'end': 131}, {'entity': 'I-ORG', 'score': np.float32(0.999137), 'index': 26, 'word': '##C', 'start': 131, 'end': 132}, {'entity': 'B-ORG', 'score': np.float32(0.9993753), 'index': 75, 'word': 'BC', 'start': 367, 'end': 369}, {'entity': 'I-ORG', 'score': np.float32(0.9989452), 'index': 76, 'word': '##C', 'start': 369, 'end': 370}, {'entity': 'B-LOC', 'score': np.float32(0.9993222), 'index': 80, 'word': 'UK', 'start': 387, 'end': 389}]\n",
      "\n",
      "Question Answering:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.00027493672678247094, 'start': 0, 'end': 69, 'answer': 'The UK manufacturing sector will continue to face \"serious challenges'}\n",
      "\n",
      "Summarization:\n",
      "[{'generated_text': 'Summarize: The UK manufacturing sector will continue to face \"serious challenges\" over the next two years, the British Chamber of Commerce (BCC) has said.  The group\\'s quarterly survey of companies found exports had picked up in the last three months of 2004 to their best levels in eight years. The rise came despite exchange rates being cited as a major concern. However, the BCC found the whole UK economy still faced \"major risks\" and warned that growth is set to slow. It recently forecast economic growth will slow from more than 3% in 2004 to a little below 2.5% in both 2005 and 2006.  Manufacturers\\' domestic sales growth fell back slightly in the quarter, the survey of 5,196 firms found. Employment in manufacturing also fell and job expectations were at their lowest level for a year.  \"Despite some positive news for the export sector, there are worrying signs for manufacturing,\" the BCC said. \"These results reinforce our concern over the sector\\'s persistent inability to sustain recovery.\" The outlook for the service soured on the UK economy in October, prompting the BCC to call for a \"hard recovery\" to stimulate growth.  In April, the BCC raised the government\\'s target for exports to account for just 18% of the UK economy, but it was expected to rise to 30% by the end of the year.  This year\\'s outlook, which also included a pledge to help the country\\'s second-largest exports, was released on Monday.  The BCC said the government should still keep its promise in the coming weeks to reduce the deficit.  It said it would meet its Â£2 billion deficit target by the end of the year. The UK was hit hard by a recession in 2007 and its trade deficit with the EU was at record levels, and the BCC said it expected the UK\\'s deficit to fall below 6% of GDP and to fall below 5% of GDP by the year\\'s end.  Overall, the BCC said growth in exports was expected to grow at its highest since the government set up the Budget in January 2005.  The figure hit 11.5% of GDP in February.  Total growth of goods, services and services exports rose by 24.8%, a 2.8% increase, to 9.8% in February.  The BCC,'}]\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Load pretrained transformer models (already loaded above)\n",
    "# Step 5: Test the models on your sample article\n",
    "if news_df is not None:\n",
    "    print(\"\\nSentiment Analysis:\")\n",
    "    print(sentiment_model(sample_headline))\n",
    "    print(\"\\nNamed Entity Recognition:\")\n",
    "    print(ner_model(sample_text[:512]))\n",
    "    print(\"\\nQuestion Answering:\")\n",
    "    question = \"What is this article about?\"\n",
    "    print(qa_model(question=question, context=sample_text[:1024]))\n",
    "    print(\"\\nSummarization:\")\n",
    "    print(summarizer(\"Summarize: \" + sample_text[:1024]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b4b1ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled 100 articles for batch processing.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ericsson sees earnings improve</td>\n",
       "      <td>Telecoms equipment supplier Ericsson has poste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kraft cuts snack ads for children</td>\n",
       "      <td>Kraft plans to cut back on advertising of prod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Worldcom boss 'left books alone'</td>\n",
       "      <td>Former Worldcom boss Bernie Ebbers, who is acc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Steady job growth continues in US</td>\n",
       "      <td>The US created fewer jobs than expected in Dec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Boeing unveils new 777 aircraft</td>\n",
       "      <td>US aircraft firm Boeing has unveiled its new l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            headline  \\\n",
       "0     Ericsson sees earnings improve   \n",
       "1  Kraft cuts snack ads for children   \n",
       "2   Worldcom boss 'left books alone'   \n",
       "3  Steady job growth continues in US   \n",
       "4    Boeing unveils new 777 aircraft   \n",
       "\n",
       "                                                text  \n",
       "0  Telecoms equipment supplier Ericsson has poste...  \n",
       "1  Kraft plans to cut back on advertising of prod...  \n",
       "2  Former Worldcom boss Bernie Ebbers, who is acc...  \n",
       "3  The US created fewer jobs than expected in Dec...  \n",
       "4  US aircraft firm Boeing has unveiled its new l...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 6: Prepare data for scaled processing\n",
    "if news_df is not None:\n",
    "    sample_df = news_df.sample(n=min(100, len(news_df)), random_state=42).reset_index(drop=True)\n",
    "    print(f\"Sampled {len(sample_df)} articles for batch processing.\")\n",
    "    display(sample_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1c88ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ericsson sees earnings improve</td>\n",
       "      <td>Good News ðŸŽ‰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kraft cuts snack ads for children</td>\n",
       "      <td>Just News ðŸ¤·</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Worldcom boss 'left books alone'</td>\n",
       "      <td>Just News ðŸ¤·</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Steady job growth continues in US</td>\n",
       "      <td>Just News ðŸ¤·</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Boeing unveils new 777 aircraft</td>\n",
       "      <td>Good News ðŸŽ‰</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            headline     category\n",
       "0     Ericsson sees earnings improve  Good News ðŸŽ‰\n",
       "1  Kraft cuts snack ads for children  Just News ðŸ¤·\n",
       "2   Worldcom boss 'left books alone'  Just News ðŸ¤·\n",
       "3  Steady job growth continues in US  Just News ðŸ¤·\n",
       "4    Boeing unveils new 777 aircraft  Good News ðŸŽ‰"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 7: Classify all articles by sentiment\n",
    "def classify_sentiment(text):\n",
    "    try:\n",
    "        result = sentiment_model(text[:512])[0]\n",
    "        label = result['label']\n",
    "        score = result['score']\n",
    "        if label == 'positive' and score > 0.7:\n",
    "            return 'Good News ðŸŽ‰'\n",
    "        elif label == 'negative' and score > 0.7:\n",
    "            return 'Bad News ðŸ‘Ž'\n",
    "        else:\n",
    "            return 'Just News ðŸ¤·'\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Sentiment classification failed: {e}\")\n",
    "        return 'Review Needed'\n",
    "\n",
    "if news_df is not None:\n",
    "    sample_df['category'] = sample_df['headline'].apply(classify_sentiment)\n",
    "    display(sample_df[['headline', 'category']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a3a78c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ericsson sees earnings improve</td>\n",
       "      <td>[##sson, ##ek, ##om, Deutsche, Tel, Eric]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kraft cuts snack ads for children</td>\n",
       "      <td>[##eo, ##si, US, ##o, Aid, ##ol, ##raft, K, Ko...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Worldcom boss 'left books alone'</td>\n",
       "      <td>[E, ##com, Bernie, David, World, Myers, ##bbe,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Steady job growth continues in US</td>\n",
       "      <td>[Department, US, Labor]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Boeing unveils new 777 aircraft</td>\n",
       "      <td>[European, US, Boeing, Airbus, Sydney, London]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            headline  \\\n",
       "0     Ericsson sees earnings improve   \n",
       "1  Kraft cuts snack ads for children   \n",
       "2   Worldcom boss 'left books alone'   \n",
       "3  Steady job growth continues in US   \n",
       "4    Boeing unveils new 777 aircraft   \n",
       "\n",
       "                                                tags  \n",
       "0          [##sson, ##ek, ##om, Deutsche, Tel, Eric]  \n",
       "1  [##eo, ##si, US, ##o, Aid, ##ol, ##raft, K, Ko...  \n",
       "2  [E, ##com, Bernie, David, World, Myers, ##bbe,...  \n",
       "3                            [Department, US, Labor]  \n",
       "4     [European, US, Boeing, Airbus, Sydney, London]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 8: Extract named entities as tags\n",
    "def extract_entities(text):\n",
    "    try:\n",
    "        entities = ner_model(text[:512])\n",
    "        tags = list(set([ent['word'] for ent in entities if ent['score'] > 0.7]))\n",
    "        return tags\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"NER failed: {e}\")\n",
    "        return []\n",
    "\n",
    "if news_df is not None:\n",
    "    sample_df['tags'] = sample_df['text'].apply(extract_entities)\n",
    "    display(sample_df[['headline', 'tags']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8bda142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>faq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ericsson sees earnings improve</td>\n",
       "      <td>{'question': 'What is the main point of this a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kraft cuts snack ads for children</td>\n",
       "      <td>{'question': 'What is the main point of this a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Worldcom boss 'left books alone'</td>\n",
       "      <td>{'question': 'What is the main point of this a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Steady job growth continues in US</td>\n",
       "      <td>{'question': 'What is the main point of this a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Boeing unveils new 777 aircraft</td>\n",
       "      <td>{'question': 'What is the main point of this a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            headline  \\\n",
       "0     Ericsson sees earnings improve   \n",
       "1  Kraft cuts snack ads for children   \n",
       "2   Worldcom boss 'left books alone'   \n",
       "3  Steady job growth continues in US   \n",
       "4    Boeing unveils new 777 aircraft   \n",
       "\n",
       "                                                 faq  \n",
       "0  {'question': 'What is the main point of this a...  \n",
       "1  {'question': 'What is the main point of this a...  \n",
       "2  {'question': 'What is the main point of this a...  \n",
       "3  {'question': 'What is the main point of this a...  \n",
       "4  {'question': 'What is the main point of this a...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 9: Generate a FAQ for each article\n",
    "def generate_faq(row):\n",
    "    try:\n",
    "        question = f\"What is the main point of this article?\"\n",
    "        answer = qa_model(question=question, context=row['text'][:1024])['answer']\n",
    "        return {'question': question, 'answer': answer}\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"FAQ generation failed: {e}\")\n",
    "        return {'question': None, 'answer': None}\n",
    "\n",
    "if news_df is not None:\n",
    "    sample_df['faq'] = sample_df.apply(generate_faq, axis=1)\n",
    "    display(sample_df[['headline', 'faq']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8d3c607",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 14.62 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 9.73 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 10.46 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 19.81 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 14.66 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 10.84 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 14.97 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 17.72 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 2.19 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 14.46 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 15.93 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 14.44 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 13.48 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 13.82 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 14.77 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 13.46 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 0.64 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 14.53 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 13.02 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 14.01 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 13.60 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 8.87 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 12.77 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 12.65 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 12.84 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 12.63 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 15.11 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 13.94 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 13.38 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 6.21 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 13.49 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 14.38 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 15.36 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 2.88 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 13.75 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 12.87 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 13.20 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 12.81 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 12.62 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 12.68 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 12.64 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 7.17 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 12.96 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 12.51 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 848.36 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 7.41 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 12.85 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 12.85 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 12.77 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 6.80 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 16.62 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 15.13 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 13.91 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 13.61 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 13.72 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 12.99 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 12.90 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 13.53 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 13.39 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 12.89 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 12.83 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 12.83 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 12.64 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 13.08 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 12.80 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 12.71 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 12.75 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 13.23 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 12.89 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 9.85 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 12.83 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 14.56 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 16.31 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 14.73 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 11.11 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 14.52 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 15.64 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 16.75 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 16.03 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 14.69 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 15.53 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 14.73 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 14.74 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 14.74 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 14.89 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 12.51 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 11.90 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 4.64 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 13.30 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 10.46 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 13.52 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 9.28 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 11.34 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 1.28 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 13.54 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 13.21 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 9.42 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 13.31 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation took 13.48 seconds\n",
      "Generation took 12.94 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ericsson sees earnings improve</td>\n",
       "      <td>Summarize: Telecoms equipment supplier Ericsso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kraft cuts snack ads for children</td>\n",
       "      <td>Summarize: Kraft plans to cut back on advertis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Worldcom boss 'left books alone'</td>\n",
       "      <td>Summarize: Former Worldcom boss Bernie Ebbers,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Steady job growth continues in US</td>\n",
       "      <td>Summarize: The US created fewer jobs than expe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Boeing unveils new 777 aircraft</td>\n",
       "      <td>Summarize: US aircraft firm Boeing has unveile...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            headline  \\\n",
       "0     Ericsson sees earnings improve   \n",
       "1  Kraft cuts snack ads for children   \n",
       "2   Worldcom boss 'left books alone'   \n",
       "3  Steady job growth continues in US   \n",
       "4    Boeing unveils new 777 aircraft   \n",
       "\n",
       "                                             summary  \n",
       "0  Summarize: Telecoms equipment supplier Ericsso...  \n",
       "1  Summarize: Kraft plans to cut back on advertis...  \n",
       "2  Summarize: Former Worldcom boss Bernie Ebbers,...  \n",
       "3  Summarize: The US created fewer jobs than expe...  \n",
       "4  Summarize: US aircraft firm Boeing has unveile...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 10: Summarize all articles\n",
    "def summarize_text(text):\n",
    "    try:\n",
    "        import time\n",
    "        start = time.time()\n",
    "        result = summarizer(\"Summarize: \" + text[:1024], max_length=60)\n",
    "        print(f\"Generation took {time.time() - start:.2f} seconds\")\n",
    "        return result[0]['generated_text']\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Summarization failed: {e}\")\n",
    "        return None\n",
    "\n",
    "if news_df is not None:\n",
    "    sample_df['summary'] = sample_df['text'].apply(summarize_text)\n",
    "    display(sample_df[['headline', 'summary']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61f4bc07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample enriched record:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>headline</th>\n",
       "      <td>Ericsson sees earnings improve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>Telecoms equipment supplier Ericsson has poste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <td>Good News ðŸŽ‰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tags</th>\n",
       "      <td>[##sson, ##ek, ##om, Deutsche, Tel, Eric]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>faq</th>\n",
       "      <td>{'question': 'What is the main point of this a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>Summarize: Telecoms equipment supplier Ericsso...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          0\n",
       "headline                     Ericsson sees earnings improve\n",
       "text      Telecoms equipment supplier Ericsson has poste...\n",
       "category                                        Good News ðŸŽ‰\n",
       "tags              [##sson, ##ek, ##om, Deutsche, Tel, Eric]\n",
       "faq       {'question': 'What is the main point of this a...\n",
       "summary   Summarize: Telecoms equipment supplier Ericsso..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 11: Visualize and review results\n",
    "if news_df is not None:\n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.countplot(x='category', data=sample_df)\n",
    "    plt.title('Distribution of News Categories')\n",
    "    plt.show()\n",
    "    print(\"\\nSample enriched record:\")\n",
    "    display(sample_df.head(1).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcd9d5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enriched dataset exported to enriched_news_sample.csv\n"
     ]
    }
   ],
   "source": [
    "# Step 12: Export enriched dataset\n",
    "if news_df is not None:\n",
    "    try:\n",
    "        sample_df.to_csv('enriched_news_sample.csv', index=False)\n",
    "        print(\"Enriched dataset exported to enriched_news_sample.csv\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Export failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314c338e",
   "metadata": {},
   "source": [
    "## 4. Display Execution Results\n",
    "\n",
    "Results for each step are shown above. Review the outputs, visualizations, and exported files for evidence of successful execution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1951c7b",
   "metadata": {},
   "source": [
    "## 5. Handle and Log Errors\n",
    "\n",
    "All errors and warnings are logged using the logging module and displayed inline for traceability and debugging."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
